name: Remove peers, pin, add peers back, pins should be everywhere
config:
  nodes: 4 # param
  selector: app=ipfs-cluster
  times: 1
  expected:
    successes: 56   # 14 x node number
    failures: 0
    timeouts: 0
  subset_partition:
    partition_type: WEIGHTED
    order: SEQUENTIAL
    percents: [50, 50]  # [departing group, staying group]
steps:
  - name: record peer multihashes of departing group
    selection:
      subset: [1]
      percent:
        order: SEQUENTIAL
        start: 1
        percent: 100
    cmd: "ipfs-cluster-ctl --enc json id | jq -r .id"
    outputs:
    - line: 0
      append_to: DEPART_MHs
  - name: record peer multihashes of staying group
    selection:
      subset: [2]
      percent:
        order: SEQUENTIAL
        start: 1
        percent: 100
    cmd: "ipfs-cluster-ctl --enc json id | jq -r .id"
    outputs:
    - line: 0
      append_to: STAY_MHs
  - name: ensure all peers see all staying peers to begin
    for:
      iter_structure: STAY_MHs
    selection:
      percent:
        order: SEQUENTIAL
        start: 1
        percent: 100
    cmd: "ipfs-cluster-ctl --enc json peers ls | jq -r .[].id > /tmp/peer-list &&
        grep -q ${STAY_MHs[%i]} /tmp/peer-list && echo 'success'"
    assertions:
      - line: 0
        should_be_equal_to: "success"
  - name: ensure all peers see all departing peers to begin
    for:
      iter_structure: DEPART_MHs
    selection:
      percent:
        order: SEQUENTIAL
        start: 1
        percent: 100
    cmd: "ipfs-cluster-ctl --enc json peers ls | jq -r .[].id > /tmp/peer-list &&
        grep -q ${DEPART_MHs[%i]} /tmp/peer-list && echo 'success'"
    assertions:
      - line: 0
        should_be_equal_to: "success"
  - name: remove all peers in the departing group from the bootstrapper
    on_node: 4 # The last node (always the bootstrapper and always in staying group)
    for:
      iter_structure: DEPART_MHs
    cmd: "ipfs-cluster-ctl peers rm ${DEPART_MHs[%i]}"
  - name: ensure all departing peers know they are removed
    selection:
      subset: [1]
      percent:
        order: SEQUENTIAL
        start: 1
        percent: 100
    cmd: "sleep 20; if [[ $(ipfs-cluster-ctl id 2>&1) = *error* ]]; then echo 'success';
         else ipfs-cluster-ctl id; fi"
    assertions:
      - line: 0
        should_be_equal_to: "success"
  - name: ensure all staying peers correctly see the departures
    for:
      iter_structure: DEPART_MHs
    selection:
      subset: [2]
      percent:
        order: SEQUENTIAL
        start: 1
        percent: 100
    cmd: "ipfs-cluster-ctl --enc json peers ls | jq -r .[].id > /tmp/peer-list;
        grep -q ${DEPART_MHs[%i]} /tmp/peer-list || echo 'not present'"
    assertions:
      - line: 0
        should_be_equal_to: "not present"
  - name: add Y items to ipfs in the staying group
    for:
      iter_structure: BOUND
      number: 4 # replace with Y (number of files to pin) using parameter feature
    cmd: "head -c 100 /dev/urandom | base64 | ipfs add -q && sleep 1"
    selection:
      subset: [2]
      range:
        order: RANDOM
        number: 1
    outputs:
    - line: 0
      append_to: HASH

  - name: pin Y items in the staying group
    for:
      iter_structure: HASH
    selection:
      subset: [2]
      range:
        order: RANDOM
        number: 1
    cmd: "ipfs-cluster-ctl pin add ${HASH[%i]} && sleep 1"

  - name: restart cluster in departed group
    selection:
      subset: [1]
      percent:
        order: SEQUENTIAL
        start: 1
        percent: 100
    cmd: "RESTART_PID=$(cat /data/ipfs-cluster/cluster-restart-pid);
        kill -CONT $RESTART_PID; sleep 15; kill -STOP $RESTART_PID"
  - name: record peer addresses of peers that will need to be readded
    selection:
      subset: [1]
      percent:
        order: SEQUENTIAL
        start: 1
        percent: 100
    cmd: "sleep 10; echo -n '/ip4/'; echo -n $(hostname -i); echo -n '/tcp/9096/ipfs/';
        echo -n $(ipfs-cluster-ctl --enc json id | jq -r .id)"
    outputs:
    - line: 0
      append_to: ADDR
  - name: record new peer multihashes of departed group
    selection:
      subset: [1]
      percent:
        order: SEQUENTIAL
        start: 1
        percent: 100
    cmd: "ipfs-cluster-ctl --enc json id | jq -r .id"
    outputs:
    - line: 0
      append_to: DEPART_NEW_MHs
  - name: wait before added departed peers back
    on_node: 1
    cmd: "sleep 20"
  - name: add back all departed peers from the bootstrapper
    for:
      iter_structure: ADDR
    on_node: 4 # the last node is the bootstrapper
    cmd: "sleep 20; ipfs-cluster-ctl peers add ${ADDR[%i]}"
  - name: ensure all peers see the peers that always stayed in cluster
    for:
      iter_structure: STAY_MHs
    selection:
      percent:
        order: SEQUENTIAL
        start: 1
        percent: 100
    cmd: "ipfs-cluster-ctl --enc json peers ls | jq -r .[].id > /tmp/peer-list &&
        grep -q ${STAY_MHs[%i]} /tmp/peer-list && echo 'success' "
    assertions:
      - line: 0
        should_be_equal_to: "success"
  - name: ensure all peers see the peers that departed
    for:
      iter_structure: DEPART_NEW_MHs
    selection:
      percent:
        order: SEQUENTIAL
        start: 1
        percent: 100
    cmd: "ipfs-cluster-ctl --enc json peers ls | jq -r .[].id > /tmp/peer-list &&
        grep -q ${DEPART_NEW_MHs[%i]} /tmp/peer-list && echo 'success' "
    assertions:
      - line: 0
        should_be_equal_to: "success"
  - name: ensure all peers see and replicate all pins
    selection:
      percent:
        order: SEQUENTIAL
        start: 1
        percent: 100
    for:
      iter_structure: HASH
    cmd: "ipfs-cluster-ctl --enc json status ${HASH[%i]}
        | jq -r '.peer_map | .[].status' | sort
        | tee /tmp/allout.txt | uniq | tee /tmp/singleout.txt
        && cat /tmp/allout.txt | wc -l && cat /tmp/singleout.txt | wc -l"
    assertions:
      - line: 0
        should_be_equal_to: "pinned"
      - line: 1
        should_be_equal_to: "4" #Number of nodes (Rep factor of 4 (all nodes) by default)
      - line: 2
        should_be_equal_to: "1" #No unpins no errors!
